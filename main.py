from ultralytics import YOLO
from paddleocr import PaddleOCR
import cv2
import numpy as np
import re

# Initialize models
yolo_model = YOLO("best.pt")
ocr = PaddleOCR(use_angle_cls=True, lang='ar', use_gpu=True)

# Arabic character translations
translations = {
    # ----------------- Digits -----------------
    '0': 'Ù ', '1': 'Ù¡', '2': 'Ù¢', '3': 'Ù£', '4': 'Ù¤',
    '5': 'Ù¥', '6': 'Ù¦', '7': 'Ù§', '8': 'Ù¨', '9': 'Ù©',

    'digit_0': 'Ù ', 'digit_1': 'Ù¡', 'digit_2': 'Ù¢', 'digit_3': 'Ù£', 'digit_4': 'Ù¤',
    'digit_5': 'Ù¥', 'digit_6': 'Ù¦', 'digit_7': 'Ù§', 'digit_8': 'Ù¨', 'digit_9': 'Ù©',

    # ----------- English Transliterations -----------
    '7aah': 'Ø­', 'Daad': 'Ø¶', 'Een': 'Ø¹', 'Heeh': 'Ù‡',
    'Kaaf': 'Ùƒ', 'Laam': 'Ù„', 'Meem': 'Ù…', 'Noon': 'Ù†',
    'Saad': 'Øµ', 'Seen': 'Ø³', 'Taa': 'Ø·', 'Wow': 'Ùˆ',
    'Yeeh': 'ÙŠ', 'Zeen': 'Ø²', 'alef': 'Ø£', 'baa': 'Ø¨',
    'daal': 'Ø¯', 'geem': 'Ø¬',

    # ----------- Short Transliteration Variants -----------
    'aa': 'Ø¹', 'g': 'Ø¬', 's': 'Ø³', 'ss': 'Øµ', 'b': 'Ø¨',
    'd': 'Ø¯', 't': 'Ø·', 'h': 'Ù‡', 'k': 'Ù‚', 'f': 'Ù',
    'n': 'Ù†', 'l': 'Ù„', 'm': 'Ù…', 'w': 'Ùˆ', 'y': 'ÙŠ', 'r': 'Ø±',

    # ------------- From Letter Dataset -------------
    'letter_ain': 'Ø¹', 'letter_alef': 'Ø£', 'letter_baa': 'Ø¨', 'letter_dal': 'Ø¯',
    'letter_faa': 'Ù', 'letter_haa': 'Ù‡Ù€', 'letter_jeem': 'Ø¬', 'letter_kaf': 'Ùƒ',
    'letter_lam': 'Ù„', 'letter_meem': 'Ù…', 'letter_noon': 'Ù†', 'letter_qaf': 'Ù‚',
    'letter_raa': 'Ø±', 'letter_saad': 'Øµ', 'letter_seen': 'Ø³', 'letter_taa2': 'Ø·',
    'letter_waaw': 'Ùˆ', 'letter_yaa': 'ÙŠ',
}


def preprocess_image(image):
    """Preprocess the image for better OCR results"""
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Apply denoising
    denoised = cv2.fastNlMeansDenoising(gray)
    
    # Enhance contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(denoised)
    
    return enhanced

def is_arabic_text(text):
    """Check if text contains Arabic characters"""
    arabic_pattern = re.compile(r'[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF]+')
    return bool(arabic_pattern.search(text))

def is_english_text(text):
    """Check if text contains English characters"""
    english_pattern = re.compile(r'[a-zA-Z]+')
    return bool(english_pattern.search(text))

def is_upper_part_text(text):
    """Check if text is likely to be from the upper part of the plate"""
    # Remove spaces and check for Ù…ØµØ± variations
    text_no_spaces = text.replace(" ", "")
    if "Ù…ØµØ±" in text_no_spaces:
        return True
        
    # Check for spaced out Ù…ØµØ± (Ù… Øµ Ø±)
    if all(char in text for char in ["Ù…", "Øµ", "Ø±"]):
        return True
        
    # Check for EGYPT variations
    if "EGYPT" in text.upper():
        return True
        
    return False

def process_ocr_result(result):
    """Process OCR results to extract letters and digits"""
    letters = ""
    digits = ""
    
    if not result:
        return None
    
    # Sort lines by vertical position (y-coordinate)
    sorted_lines = sorted(result[0], key=lambda x: x[0][0][1])  # Sort by y-coordinate
    
    for line in sorted_lines:
        text = line[1][0].strip()
        
        # Skip English text
        if is_english_text(text):
            continue
            
        # Skip if it's likely to be the upper part text
        if is_upper_part_text(text):
            continue
            
        # Process only Arabic text and numbers
        for char in text:
            translated = translations.get(char, char)
            if translated.isnumeric():
                digits += translated
            elif translated.strip() and is_arabic_text(translated):
                letters += translated
    
    if not (letters or digits):
        return None
        
    return letters[::-1] + " " + digits[::-1]

def detect_and_ocr(image_path):
    """Main function to detect and recognize license plates"""
    try:
        # Read and validate image
        image = cv2.imread(image_path)
        if image is None:
            print("âŒ Error: Could not read image")
            return
            
        # Detect license plate
        results = yolo_model(image)[0]
        
        for box in results.boxes:
            class_id = int(box.cls[0])
            class_name = yolo_model.names[class_id]

            if class_name == "License Plate":
                # Extract plate region
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                plate_img = image[y1:y2, x1:x2]
                
                # Preprocess plate image
                processed_plate = preprocess_image(plate_img)
                
                # Perform OCR
                result = ocr.ocr(processed_plate, cls=True)
                
                # Process OCR results
                final_text = process_ocr_result(result)
                
                if final_text:
                    print("ğŸ” Ù„ÙˆØ­Ø© Ø§Ù„ØªØ±Ø®ÙŠØµ (Ø§Ù„Ø­Ø±ÙˆÙ Ø«Ù… Ø§Ù„Ø£Ø±Ù‚Ø§Ù…):", final_text)
                    
                    # Draw results
                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(image, final_text, (x1, y1 - 10), 
                              cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
                    
                    # Show results
                    cv2.imshow("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", processed_plate)
                    cv2.imshow("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù…Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©", image)
                    cv2.waitKey(0)
                    cv2.destroyAllWindows()
                else:
                    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ ØµØ§Ù„Ø­")
                break
        else:
            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù„ÙˆØ­Ø© ØªØ±Ø®ÙŠØµ")
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {str(e)}")

# Test the function
detect_and_ocr("Images\\img36.jpg")