from ultralytics import YOLO
from paddleocr import PaddleOCR
import cv2
import numpy as np
from basicsr.archs.rrdbnet_arch import RRDBNet
from realesrgan import RealESRGANer
import torch
from PIL import Image
import os
import mysql.connector
from datetime import datetime
import uuid

print("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ YOLO
try:
    yolo_model = YOLO("best.pt")
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ YOLO Ø¨Ù†Ø¬Ø§Ø­")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ YOLO: {e}")
    exit()

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ PaddleOCR
try:
    ocr = PaddleOCR(use_angle_cls=True, lang='ar', use_gpu=True)
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ PaddleOCR Ø¨Ù†Ø¬Ø§Ø­")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ PaddleOCR: {e}")
    exit()

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Real-ESRGAN
try:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø²: {device}")
    
    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)
    model_path = 'Real-ESRGAN/weights/RealESRGAN_x4plus.pth'
    
    if not os.path.exists(model_path):
        print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {model_path}")
        exit()
        
    upsampler = RealESRGANer(
        scale=4,
        model_path=model_path,
        model=model,
        tile=200,
        tile_pad=10,
        pre_pad=0,
        device=device
    )
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Real-ESRGAN Ø¨Ù†Ø¬Ø§Ø­")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù„Ù‰ ØµÙˆØ±Ø© ØµØºÙŠØ±Ø©
    test_img = np.zeros((100, 100, 3), dtype=np.uint8)
    enhanced, _ = upsampler.enhance(test_img, outscale=4)
    print("âœ… ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ù…ÙˆØ¯ÙŠÙ„ Real-ESRGAN Ø¨Ù†Ø¬Ø§Ø­")
    
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Real-ESRGAN: {e}")
    exit()

print("\nâœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­\n")

# Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø£Ø­Ø±Ù
translations = {
    
}

def connect_to_db():
    """Ø§Ù„Ø±Ø¨Ø· Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    try:
        conn = mysql.connector.connect(
            host='localhost',
            user='root',
            password='',
            database='anpr'
        )
        return conn
    except mysql.connector.Error as err:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {err}")
        return None

def save_plate_and_vehicle(letters, digits, vehicle_image):
    """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„ÙˆØ­Ø© ÙˆØ§Ù„Ù…Ø±ÙƒØ¨Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    try:
        conn = connect_to_db()
        if not conn:
            return

        cursor = conn.cursor()

        # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„ÙˆØ­Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ plates
        sql_plate = "INSERT IGNORE INTO plates (letters, numbers) VALUES (%s, %s)"
        cursor.execute(sql_plate, (letters[::-1], digits[::-1]))
        plate_id = cursor.lastrowid  # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ID Ø§Ù„Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
        conn.commit()

        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„ÙˆØ­Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ plates Ø¨Ø§Ù„Ù€ ID: {plate_id}")

        # Ø­ÙØ¸ ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ vehicles (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        if vehicle_image is not None:
            image_path = f"images/{uuid.uuid4()}.jpg"  # ØªÙˆÙ„ÙŠØ¯ Ù…Ø³Ø§Ø± ÙØ±ÙŠØ¯ Ù„Ù„ØµÙˆØ±Ø©
            cv2.imwrite(image_path, vehicle_image)  # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©

            # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
            detected_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            sql_vehicle = "INSERT INTO vehicles (plate_id, image_path, detected_at) VALUES (%s, %s, %s)"
            cursor.execute(sql_vehicle, (plate_id, image_path, detected_at))
            conn.commit()

            print(f"âœ… ØªÙ… Ø­ÙØ¸ ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ vehicles Ù…Ø¹ Ø§Ù„Ù€ ID: {plate_id}")

        cursor.close()
        conn.close()
    except mysql.connector.Error as err:
        print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {err}")

def calculate_image_quality(image):
    """Ø­Ø³Ø§Ø¨ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©"""
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    contrast = np.std(gray)
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    sharpness = np.var(laplacian)
    return contrast, sharpness

def enhance_plate_image(plate_img):
    try:
        contrast, sharpness = calculate_image_quality(plate_img)
        plate_rgb = cv2.cvtColor(plate_img, cv2.COLOR_BGR2RGB)
        
        if contrast < 50 or sharpness < 100:
            enhanced, _ = upsampler.enhance(plate_rgb, outscale=4)
            print("âœ… ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Real-ESRGAN")
        else:
            enhanced = plate_rgb
            print("âœ… Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ø¶Ø­Ø©ØŒ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Real-ESRGAN")
        
        lab = cv2.cvtColor(enhanced, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        cl = clahe.apply(l)
        enhanced_lab = cv2.merge((cl,a,b))
        enhanced = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)
        enhanced_img = cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR)
        
        if contrast < 50 or sharpness < 100:
            enhanced_img = cv2.fastNlMeansDenoisingColored(enhanced_img, None, 10, 10, 7, 21)
        
        return enhanced_img
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©: {e}")
        return plate_img

def is_english(text):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"""
    return all(ord('A') <= ord(c) <= ord('Z') or ord('a') <= ord(c) <= ord('z') for c in text)

def clean_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨ ÙÙŠÙ‡Ø§"""
    text = text.replace("Ù…ØµØ±", "")
    text = text.strip()
    return text

def detect_and_ocr(image_path):
    try:
        image = cv2.imread(image_path)
        if image is None:
            print("âŒ Ø®Ø·Ø£: Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©")
            return
            
        height, width = image.shape[:2]
        if height > 1200 or width > 1600:
            scale = min(1200/height, 1600/width)
            new_height = int(height * scale)
            new_width = int(width * scale)
            image = cv2.resize(image, (new_width, new_height))
            print(f"âœ… ØªÙ… ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ {new_width}x{new_height}")
            
        results = yolo_model(image)[0]

        for box in results.boxes:
            class_id = int(box.cls[0])
            class_name = yolo_model.names[class_id]

            if class_name == "License Plate":
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                margin = 10
                h, w = image.shape[:2]
                x1 = max(0, x1 - margin)
                y1 = max(0, y1 - margin)
                x2 = min(w, x2 + margin)
                y2 = min(h, y2 + margin)
                
                plate_img = image[y1:y2, x1:x2]

                cv2.imshow("Ø§Ù„Ù„ÙˆØ­Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", plate_img)
                cv2.waitKey(1)

                enhanced_plate = enhance_plate_image(plate_img)
                
                cv2.imshow("Ø§Ù„Ù„ÙˆØ­Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø³ÙŠÙ†", enhanced_plate)
                cv2.waitKey(1)

                result = ocr.ocr(enhanced_plate, cls=True)

                if result and len(result) > 0 and result[0]:
                    letters = ""
                    digits = ""

                    for line in result[0]:
                        if len(line) >= 2 and line[1]:
                            text = clean_text(line[1][0])
                            

                            if is_english(text):
                                continue
                                
                            for char in text:
                                if is_english(char):
                                    continue
                                    
                                translated = translations.get(char, char)
                                if translated.isnumeric():
                                    digits += translated
                                elif translated.strip():
                                    letters += translated

                    letters = clean_text(letters)
                    
                    if letters or digits:
                        final_text = letters[::-1] + " " + digits[::-1]
                        final_text = clean_text(final_text)
                        
                        if final_text.strip():
                            print("ğŸ” Ù„ÙˆØ­Ø© Ø§Ù„ØªØ±Ø®ÙŠØµ (Ø§Ù„Ø­Ø±ÙˆÙ Ø«Ù… Ø§Ù„Ø£Ø±Ù‚Ø§Ù…):", final_text)

                            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            cv2.putText(image, final_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                                        1.2, (0, 255, 0), 3, cv2.LINE_AA)

                            save_plate_and_vehicle(letters, digits, image)
                            
                            cv2.imshow("Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©", image)
                            cv2.waitKey(0)
                            cv2.destroyAllWindows()
                        else:
                            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ ØµØ§Ù„Ø­ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ")
                    else:
                        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ ØµØ§Ù„Ø­")
                else:
                    print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ")
                break
        else:
            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù„ÙˆØ­Ø© ØªØ±Ø®ÙŠØµ")
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {str(e)}")

# ØªØ¬Ø±Ø¨Ø©
detect_and_ocr("Images\\img11.jpg")
